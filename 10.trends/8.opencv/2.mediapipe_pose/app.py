from flask import Flask, render_template, Response, jsonify
import cv2
import mediapipe as mp
import time
import atexit

app = Flask(__name__)

mp_pose = mp.solutions.pose
pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)
mp_drawing = mp.solutions.drawing_utils

cap = cv2.VideoCapture(0)
latest_pose_summary = "No pose detected yet."

def summarize_pose(landmarks, frame_width=640, frame_height=480):
    # ìƒë°˜ì‹  ìœ„ì£¼ ê´€ì ˆë§Œ ì¶”ì¶œ
    key_joints = {
        "left_shoulder": landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER],
        "left_elbow": landmarks[mp_pose.PoseLandmark.LEFT_ELBOW],
        "left_wrist": landmarks[mp_pose.PoseLandmark.LEFT_WRIST],
        "right_shoulder": landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER],
        "right_elbow": landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW],
        "right_wrist": landmarks[mp_pose.PoseLandmark.RIGHT_WRIST],
    }

    summary = []
    visible_parts = 0
    
    # ì£¼ìš” ê´€ì ˆ visibility í™•ì¸ (0.5 ì´ìƒì´ë©´ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼)
    for name, lm in key_joints.items():
        if lm.visibility > 0.5:  # visibility ì„ê³„ê°’ ì¶”ê°€
            # ì •ê·œí™”ëœ ì¢Œí‘œ(0.0~1.0, 1.0ë³´ë‹¤ í¬ë©´ í™”ë©´ ë°–)ë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
            pixel_x = int(lm.x * frame_width)
            pixel_y = int(lm.y * frame_height)
            summary.append(f"{name}: ì •ê·œí™”({lm.x:.2f}, {lm.y:.2f}) / í”½ì…€({pixel_x}, {pixel_y})")
            visible_parts += 1
        else:
            summary.append(f"{name}: not visible")
    
    if visible_parts == 0:
        return "ì£¼ìš” ì‹ ì²´ ë¶€ìœ„ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìƒë°˜ì‹ ì´ ë³´ì´ë„ë¡ ì¹´ë©”ë¼ ìœ„ì¹˜ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”."
        
    return "\n".join(summary)

def generate_frames():
    global latest_pose_summary
    last_update_time = time.time()

    while True:
        success, frame = cap.read()
        if not success:
            break

        # ì¢Œìš° ë°˜ì „ (ê±°ìš¸ì²˜ëŸ¼ ë³´ì´ë„ë¡) - ë‹¨ ì¢Œí‘œê°’ë„ left/right ë³€ê²½í•´ì„œ ë§¤ì¹­í•´ì•¼í•¨
        # frame = cv2.flip(frame, 1)
        
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(image)

        annotated_frame = frame.copy()
        if results.pose_landmarks:
            mp_drawing.draw_landmarks(
                annotated_frame, # ê·¸ë¦´ ëŒ€ìƒ ì´ë¯¸ì§€ (BGR)
                results.pose_landmarks, # í¬ì¦ˆ ì¶”ì • ê²°ê³¼ (landmarks)
                mp_pose.POSE_CONNECTIONS, # ê´€ì ˆì„ ì„ ìœ¼ë¡œ ì—°ê²°í•  ì •ì˜
                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=2), # ëœë“œë§ˆí¬(ì )ì˜ ìŠ¤íƒ€ì¼
                mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2) # ê´€ì ˆ ì—°ê²°ì„ ì˜ ìŠ¤íƒ€ì¼
            )

            # 1ì´ˆë§ˆë‹¤ ìš”ì•½ ì—…ë°ì´íŠ¸
            now = time.time()
            if now - last_update_time > 1:
                latest_pose_summary = summarize_pose(results.pose_landmarks.landmark)
                last_update_time = now
        else:
            latest_pose_summary = "í¬ì¦ˆê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        ret, buffer = cv2.imencode('.jpg', annotated_frame)
        frame = buffer.tobytes()

        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')


@app.route('/')
def index():
    return render_template('index.html')

@app.route('/video_feed')
def video_feed():
    return Response(generate_frames(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/pose_summary')
def pose_summary():
    return jsonify({"summary": latest_pose_summary})

@app.route('/shutdown')
def shutdown():
    cap.release()
    return "Camera Released"

@atexit.register
def release_camera_on_exit():
    if cap.isOpened():
        print("ğŸ”’ Cleaning up: Releasing webcam...")
        cap.release()
        print("âœ… Webcam released.")

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0')
